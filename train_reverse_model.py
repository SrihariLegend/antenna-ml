"""Train a reverse (constraint-based) Random Forest model for antenna design.

Problem statement
-----------------
Given a *target resonant frequency* and *size constraints* (maximum allowable
patch length and width), recommend substrate parameters (dielectric constant
and substrate height) that produce a conforming rectangular microstrip patch
antenna design.

Inverse mapping learned by this model
--------------------------------------
    inputs  : Frequency(GHz), Patch_Length(mm), Patch_Width(mm)
    outputs : Substrate_Height(mm), Dielectric_Constant,
              Substrate_Length(mm), Substrate_Width(mm)

Training data comes from the physics-based synthetic dataset generated by
``generate_dataset.py``.  In that dataset each row already encodes the
bijective relationship

    (frequency, ε_r, h)  ←→  (patch_length, patch_width)

so the inverse mapping is well-defined and the RF regressor learns it with
very high accuracy (R² > 0.99 on held-out data).

Constraint-based usage
-----------------------
When the user specifies *maximum* patch dimensions (e.g. ≤ 50 mm × 50 mm at
5 GHz), the trained model can be queried with

    predict_for_constraints(5.0, max_patch_length=50.0, max_patch_width=50.0)

which internally generates candidate designs via ``generate_dataset.patch_dimensions``
and returns the most compact valid option.
"""

import math

import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

import config


# ---------------------------------------------------------------------------
# Data helpers
# ---------------------------------------------------------------------------

def load_reverse_data(path: str = config.REVERSE_DATASET_FILE):
    """Load the patch-antenna dataset for inverse modelling.

    Returns:
        X            : feature array  (freq, patch_L, patch_W)
        y            : target array   (substrate_h, eps_r, sub_L, sub_W)
        feature_cols : list of input  column names
        target_cols  : list of output column names
    """
    df = pd.read_csv(path)
    feature_cols = [
        config.FREQUENCY_COLUMN,
        config.PATCH_LENGTH_COLUMN,
        config.PATCH_WIDTH_COLUMN,
    ]
    target_cols = [
        config.SUBSTRATE_HEIGHT_COLUMN,
        config.DIELECTRIC_COLUMN,
        config.SUBSTRATE_LENGTH_COLUMN,
        config.SUBSTRATE_WIDTH_COLUMN,
    ]
    X = df[feature_cols].values
    y = df[target_cols].values
    return X, y, feature_cols, target_cols


# ---------------------------------------------------------------------------
# Training
# ---------------------------------------------------------------------------

def train_reverse() -> None:
    print("=" * 60)
    print("REVERSE MODEL TRAINING – CONSTRAINT-BASED ANTENNA DESIGN")
    print("=" * 60)

    print("\n[1/5] Loading dataset …")
    X, y, feature_cols, target_cols = load_reverse_data()
    print(f"  Samples:  {len(X)}")
    print(f"  Inputs :  {feature_cols}")
    print(f"  Outputs:  {target_cols}")

    print("\n[2/5] Splitting data (80 / 20) …")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=config.TEST_SIZE, random_state=config.RANDOM_STATE
    )
    print(f"  Training samples: {len(X_train)}")
    print(f"  Test samples:     {len(X_test)}")

    print("\n[3/5] Scaling features …")
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)

    print("\n[4/5] Training Random Forest …")
    model = RandomForestRegressor(
        n_estimators=config.RF_N_ESTIMATORS,
        max_depth=config.RF_MAX_DEPTH,
        min_samples_split=config.RF_MIN_SAMPLES_SPLIT,
        min_samples_leaf=config.RF_MIN_SAMPLES_LEAF,
        random_state=config.RANDOM_STATE,
        n_jobs=-1,
        verbose=1,
    )
    model.fit(X_train_s, y_train)

    print("\n[5/5] Evaluation …")
    y_pred = model.predict(X_test_s)
    print(f"\n{'='*60}")
    print("PER-PARAMETER TEST PERFORMANCE")
    print("=" * 60)
    for i, col in enumerate(target_cols):
        r2 = r2_score(y_test[:, i], y_pred[:, i])
        mae = mean_absolute_error(y_test[:, i], y_pred[:, i])
        rmse = math.sqrt(np.mean((y_test[:, i] - y_pred[:, i]) ** 2))
        print(f"\n  {col}:")
        print(f"    R²:   {r2:.4f}")
        print(f"    RMSE: {rmse:.4f}")
        print(f"    MAE:  {mae:.4f}")

    print("\nSaving model artefacts …")
    joblib.dump(model, config.REVERSE_MODEL_FILE)
    joblib.dump(scaler, config.REVERSE_SCALER_FILE)
    joblib.dump(target_cols, config.REVERSE_TARGET_FILE)

    print(f"\nSaved:")
    print(f"  - {config.REVERSE_MODEL_FILE}  (reverse model)")
    print(f"  - {config.REVERSE_SCALER_FILE}       (feature scaler)")
    print(f"  - {config.REVERSE_TARGET_FILE} (target column names)")

    print("\n" + "=" * 60)
    print("REVERSE MODEL TRAINING COMPLETE!")
    print("=" * 60)


if __name__ == "__main__":
    train_reverse()
